# Alignment with the draft implementing act on AI regulatory sandboxes

This document analyses the extent to which the draft implementing act on AI regulatory sandboxes under the EU AI Act aligns with the common requirements outlined in `01-common-requirements.md`.

The assessment is structured along three categories:
- requirements that are clearly addressed,
- requirements that are partially addressed or addressed at a procedural level,
- and requirements that are not explicitly addressed in an operational or enforceable manner.

The intent is not to evaluate the draft from a legal perspective, but to assess its practical and architectural alignment with the functioning of regulatory sandboxes as effective learning and transition environments.

---

## Addressed requirements 

### Access to regulatory sandboxes and procedural clarity

The draft implementing act provides a clear procedural framework for the establishment and operation of AI regulatory sandboxes, including:
- defined application and selection processes,
- time-bound participation,
- and the role of competent authorities in supervision.

These elements contribute to transparency, predictability, and equal access, which are foundational for trust in sandbox mechanisms.

---

### Regulatory supervision and controlled conditions

The draft explicitly frames AI regulatory sandboxes as controlled environments operating under regulatory supervision.  
This aligns with the requirement to create safe spaces for experimentation while maintaining oversight and accountability.

The possibility to conduct sandbox activities under real-world conditions, where appropriate, further supports meaningful regulatory learning.

---

### Documentation and reporting obligations

Requirements related to documentation, reporting, and the generation of outputs from sandbox activities are addressed at a procedural level.

Such obligations support traceability of activities and enable authorities to derive insights from sandbox participation, contributing to the broader regulatory learning objectives of the AI Act.

---

## Partially addressed requirements 

### Interoperability

The draft recognises the importance of avoiding fragmentation and promoting coherence across AI regulatory sandboxes. However, interoperability is primarily addressed as a governance objective rather than as an operational requirement.

While coordination and information exchange are encouraged, the draft does not specify:
- technical interoperability expectations,
- interface consistency,
- or mechanisms to ensure transferability of sandbox outcomes across organisational or national contexts.

As a result, interoperability remains dependent on implementation choices at the level of individual competent authorities.

---

### Production parity

The draft enables experimentation in controlled and, in some cases, real-world conditions.  
However, it does not explicitly address the degree of alignment between sandbox environments and later production environments.

Aspects such as:
- architectural consistency,
- operational responsibilities,
- and alignment of security and monitoring practices

are not defined in a way that ensures findings from sandbox activities remain directly applicable to subsequent deployment contexts.

---

### Data governance

Data protection and compliance with existing legal frameworks are acknowledged, and the involvement of relevant supervisory authorities is foreseen where applicable.

At the same time, data governance is addressed primarily at a high level. The draft does not provide operational clarity on:
- data lifecycle management within sandboxes,
- traceability of data flows,
- or the handling of changing legal or factual conditions during sandbox operation.

---

## Not addressed requirements 

### Unlearning and reversibility of learning effects

While data protection and lawful processing are referenced, the draft does not explicitly address the reversibility of learning effects in AI systems.

Considerations such as:
- how to handle situations where data used during sandbox activities must later be excluded,
- or how to document and demonstrate corresponding adjustments to system behaviour,

are not covered as part of the sandbox framework.

---

### Security-by-design baseline

Security considerations are referenced in relation to risk management and safeguards.  
However, the draft does not establish a shared security-by-design baseline for sandbox environments.

Without such a baseline, security practices may vary significantly between sandboxes, limiting comparability and the reliability of security-related findings.

---

### Versioned and auditable sandbox baseline

Although reporting and documentation are required, the draft does not explicitly address the need for a versioned and auditable baseline covering:
- sandbox configurations,
- applied rules and assumptions,
- and changes over time.

The absence of such an explicit baseline limits the ability to relate outcomes and regulatory insights to specific sandbox states or configurations.

---

## Summary

**The draft implementing act primarily prepares to establish a procedural framework. However, for AI regulatory sandboxes to function as effective learning and transition instruments, procedural clarity alone is not sufficient without explicit operational and technical reference points that ensure comparability, transferability, and production relevance.**

### Absence of an operational definition

**As set out in [Regulation (EU) 2024/1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689), AI regulatory sandboxes describes the purpose and intended function of AI regulatory sandboxes primarily through functional and teleological language. In particular, AI regulatory sandboxes are characterised as controlled frameworks established by competent authorities to enable the development, training, validation, and testing of innovative AI systems under regulatory supervision and for a limited time before market placement.**

**However, the regulatory framework does not provide a consolidated operational or technical definition of what constitutes an AI regulatory sandbox in practice. The description remains purpose-driven rather than definitional and does not specify minimum structural, technical, or organisational characteristics that would distinguish regulatory sandboxes from other forms of pilot environments, testbeds, or innovation programmes.**

**As a result, substantial interpretative discretion is delegated to competent authorities at national or sectoral level. While this flexibility supports contextual adaptation, it also introduces the risk of heterogeneous implementations that may differ significantly in scope, maturity, and operational depth.**

**From a regulatory learning perspective, the absence of a shared operational definition may limit comparability across sandbox initiatives and reduce the transferability of insights between jurisdictions, sectors, and implementation cycles. This becomes particularly relevant where regulatory sandboxes are expected to function not only as isolated experimentation environments but also as instruments for systematic learning and transition towards compliant market deployment.**
**

### Partial coverage of interoperability and operational transferability

**Several requirements relevant to interoperability, operational transferability, and long-term regulatory learning are only partially addressed or remain implicit in the draft implementing act. As a result, the practical effectiveness of AI regulatory sandboxes is likely to depend largely on subsequent implementation choices by competent authorities and participating organisations.**

### Scope and intent of this assessment

This assessment serves as a neutral reference for further discussion and does not constitute a legal evaluation of the draft implementing act.

