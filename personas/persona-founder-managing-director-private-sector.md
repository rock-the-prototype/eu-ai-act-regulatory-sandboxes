# Persona: Sascha Block — Founder & Managing Director, Private Sector (INZTITUT GmbH)

I translate the EU AI Act’s regulatory sandbox intent into implementable, interoperable architecture and evidence patterns — designed for large-scale, cross-organisation rollout.

## Identity, role and function
- Founder & Managing Director (sole shareholder), INZTITUT GmbH (private sector)  
- Author: [BLOCK, Sascha.Large-Scale Agile Frameworks: Agile Frameworks, agile Infrastruktur und pragmatische Lösungen zur digitalen Transformation.](https://link.springer.com/book/10.1007/978-3-662-62048-9) Berlin, Heidelberg: Springer Vieweg, 2023. ISBN 978-3-662-62047-2 (Print). ISBN 978-3-662-62048-9 (eBook). DOI 10.1007/978-3-662-62048-9. [Verfügbar unter: SpringerLink (DE)](https://link.springer.com/book/10.1007/978-3-662-62048-9)
- Author: [BLOCK, Sascha.Large-Scale Agile Frameworks: Agile Frameworks, Agile Infrastructure and Pragmatic Solutions for Digital Transformation.](https://link.springer.com/book/10.1007/978-3-662-67782-7)  Berlin, Heidelberg: Springer, 2023. ISBN 978-3-662-67781-0 (Print). ISBN 978-3-662-67782-7 (eBook). DOI 10.1007/978-3-662-67782-7. [Available at: SpringerLink (EN)](https://link.springer.com/book/10.1007/978-3-662-67782-7) 

## Primary objectives 
- Role: Standards & Interoperability Architect, Creator of Rock the Prototype - Prototyping & Software development
- Mission: Strengthen common good outcomes by reducing fragmentation and enabling portability across organisations and Member States.
- Values: interoperability, transparency of obligations, vendor neutrality.
- Focus: Author and Lead architect of [dsl-core](https://github.com/rock-the-prototype/dsl-core) — an open, formal standard specification for defining software requirements in a deterministic, machine-readable, Git-versioned and audit-ready way, enabling systematic verification of implementations in regulated and trustworthy digital systems.

  I work on an open, formal standard that enables software requirements to be defined in a revision-safe, machine-readable, versioned and auditable form — so trustworthy digitalisation becomes verifiable, not interpretive.

  *DSL Core* is an *open standards specification* to define requirements formally, deterministically and traceably over time. By versioning requirements in Git and making them explicit and testable, DSL Core provides a normative basis against which implementations can be systematically verified.

  Goal:
  I develop a domain-specific language (DSL) that:
  * is human- and machine-readable,
  * represents syntactically unambiguous, verifiable requirements (AFOs),
  * is testable and versionable (Git integration),
  * can be automatically validated and audited (CI/CD),
  * and can express semantic governance rules, exclusions, negative rules, etc.


## Why this perspective is relevant for the EU AI Act
- The EU AI Act is a large-scale regulatory system by design: many actors, many domains, many implementations.
- Regulatory sandboxes and large-scale pilots only scale if interfaces, artefacts, and evidence are portable across organisations.
- Therefore, the practical question is: what is the minimum interoperable baseline that makes outcomes repeatable and production-relevant?

## Why this matters for every European software company
Modern software delivery is structurally dependent on external resources: cloud platforms, identity providers, managed services, supply chains, and dominant ecosystems operated by gatekeepers and hyperscalers. For European companies, this makes interoperability, transparency, and auditability strategic capabilities — not technical preferences.

From this perspective, it is essential that publicly financed digital components evolve as digital public goods:
portable, inspectable, and standards-based — so that trust, security, and long-term viability remain verifiable across organisations and over time.

## Public goods versus black-box solutions
In publicly funded digital health infrastructure, long-term trust and resilience depend on whether critical components remain interoperable and verifiable across organisations. When essential digital capabilities are delivered as non-transparent, non-portable solutions, auditability and reuse become structurally constrained.

From a public-law perspective, publicly financed digital components should function as digital public goods:
transparent by default, audit-ready by design, and interoperable as a baseline.
These properties are prerequisites for trust, security, and long-term viability in public-law systems.

## Implications for AI regulatory sandboxes
From this explicitly named public-law perspective, AI regulatory sandboxes matter insofar as they:
- enable early validation of security, privacy, and interoperability assumptions,
- reduce regulatory and operational uncertainty before large-scale deployment,
- and support architectural decisions that shape critical public healthcare infrastructure.

Their primary value is not experimentation for its own sake, but the prevention of irreversible design errors in systems that must operate reliably at national scale and under public responsibility.

## Focus in this repository
- Turn sandbox obligations into operational requirements, controls, and evidence artefacts.
- Define portability: which artefacts must be reusable across authorities and programmes.
- Specify maturity gates: measurable exit criteria from sandbox → production.
- Keep contributions vendor-neutral: outcomes and interfaces over tool choices.

## Typical questions that need to be answered in the context of AI Act Sandbox environments
- What must be provable for sandbox results to be accepted as production-relevant?
- Which artefacts are authoritative (plan, logs, test reports, incident handling, oversight records)?
- Where does oversight become operational (monitoring, escalation, post-market feedback loops)?
- What is the minimum interoperability baseline that avoids fragmentation?

## Outputs / artefacts as part of an answer in the context of AI Act Sandbox environments
- Mapping tables: regulatory text → operational requirement → control → test → evidence
- Interoperability baseline checklist (data, APIs, identity/access, logging, reporting)
- Reference architecture templates (roles, components, interfaces, evidence flows)
- Maturity gates with measurable exit criteria (sandbox phases → production readiness)
